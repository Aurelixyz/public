import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.header import Header
from email.mime.image import MIMEImage
import configparser
import pyodbc
import pandas as pd
from datetime import datetime, timedelta
import codecs
import matplotlib.pyplot as plt
import seaborn as sns
import os
import numpy as np
from matplotlib.colors import LinearSegmentedColormap
import io

# === Krok 1: Wczytaj dane konfiguracyjne ===
config = configparser.ConfigParser()
try:
    with codecs.open('config.ini', 'r', encoding='utf-8') as f:
        config.read_file(f)
except FileNotFoundError:
    print("❌ Błąd: Plik config.ini nie został znaleziony. Upewnij się, że znajduje się w tym samym katalogu co skrypt.")
    exit()
except Exception as e:
    print(f"❌ Błąd podczas wczytywania pliku config.ini: {e}")
    exit()

sender_email = config.get('EMAIL', 'Sender')
receiver_email = config.get('EMAIL', 'Receiver')
smtp_server = config.get('EMAIL', 'SMTPServer')
subject = config.get('EMAIL', 'Subject')
conn_str = config.get('DATABASE', 'ConnectionString')
generate_plots = config.getboolean('REPORT_SETTINGS', 'GeneratePlots', fallback=True)

try:
    TOTAL_LIMIT = config.getint('REPORT_SETTINGS', 'TotalConsultantLimit')
    DEPT_LIMIT = config.getint('REPORT_SETTINGS', 'DepartmentConsultantLimit')
except (configparser.Error, ValueError):
    print("⚠️ Ostrzeżenie: Nie można odczytać limitów z config.ini. Używam domyślnych wartości (18/3).")
    TOTAL_LIMIT = 18
    DEPT_LIMIT = 3

# === Krok 2: Wczytaj zapytanie SQL z pliku ===
query = ""
try:
    with open("zapytanieREPLIKA.sql", "r", encoding="utf-8") as file:
        query = file.read()
except FileNotFoundError:
    print("❌ Błąd: Plik zapytanieREPLIKA.sql nie został znaleziony.")
    exit()
except Exception as e:
    print(f"❌ Błąd podczas wczytywania pliku zapytanieREPLIKA.sql: {e}")
    exit()

# === Krok 3: Połącz się z bazą danych i wykonaj zapytanie ===
df = pd.DataFrame()
try:
    conn = pyodbc.connect(conn_str)
    cursor = conn.cursor()
    cursor.execute(query)
    rows = cursor.fetchall()
    columns = [column[0] for column in cursor.description]
    df = pd.DataFrame.from_records(rows, columns=columns)
    conn.close()
    print("✅ Dane zostały pomyślnie pobrane z bazy danych.")
except pyodbc.Error as ex:
    sqlstate = ex.args[0]
    print(f"❌ Błąd połączenia z bazą danych lub wykonania zapytania: {sqlstate}")
    exit()
except Exception as e:
    print(f"❌ Wystąpił nieoczekiwany błąd podczas operacji na bazie danych: {e}")
    exit()

if df.empty:
    print("⚠️ Ostrzeżenie: Brak danych do przetworzenia. Raport zostanie wygenerowany z pustymi danymi.")

# === Krok 4: Przetwórz dane ===
if not df.empty:
    df['StatusDateTime'] = pd.to_datetime(df['StatusDateTime'])
    df['EndDateTime'] = pd.to_datetime(df['EndDateTime'])
else:
    dummy_date = datetime.now()
    # ZMIANA: Dodanie nowej kolumny do pustego DataFrame
    df = pd.DataFrame(columns=['StatusDateTime', 'EndDateTime', 'UserId', 'Wydzial', 'PrzelozonyLoginWindows'])
    df.loc[0] = [dummy_date, dummy_date + timedelta(minutes=1), 'DummyUser', 'WZK1', 'DummyPrzelozony']

def calculate_seconds(row):
    start = row['StatusDateTime']
    end = row['EndDateTime']
    intervals = []
    while start < end:
        next_hour = (start + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)
        if next_hour > end:
            next_hour = end
        seconds = (next_hour - start).total_seconds()
        # ZMIANA: Dodanie nowej kolumny do krotki
        intervals.append((start.hour, seconds, row['UserId'], row['Wydzial'], row['PrzelozonyLoginWindows']))
        start = next_hour
    return intervals

intervals = []
if not df.empty:
    for _, row in df.iterrows():
        intervals.extend(calculate_seconds(row))

# ZMIANA: Dodanie nowej kolumny do intervals_df
intervals_df = pd.DataFrame(intervals, columns=['Hour', 'Seconds', 'UserId', 'Wydzial', 'PrzelozonyLoginWindows'])
grouped = intervals_df.groupby('Hour').agg({'Seconds': 'sum'}).reset_index()
unique_users = intervals_df.groupby('Hour')['UserId'].nunique().reset_index()
unique_users.columns = ['Hour', 'UniqueConsultants']
grouped = pd.merge(grouped, unique_users, on='Hour', how='left').fillna(0)
all_hours = pd.DataFrame({'Hour': range(24)})
grouped = pd.merge(all_hours, grouped, on='Hour', how='left').fillna(0)

def seconds_to_minutes(seconds):
    return round(seconds / 60)

grouped['Seconds'] = grouped['Seconds'].apply(seconds_to_minutes)
departments = ['WZK1', 'WZK2', 'WZK3', 'WZF', 'WNT', 'WZP']
for dept in departments:
    dept_seconds = intervals_df[intervals_df['Wydzial'] == dept].groupby('Hour')['Seconds'].sum().reset_index()
    dept_seconds.columns = ['Hour', dept]
    grouped = pd.merge(grouped, dept_seconds, on='Hour', how='left').fillna(0)
    grouped[dept] = grouped[dept].apply(seconds_to_minutes)

def max_simultaneous_consultants(df_current_hour, hour):
    base_date = df_current_hour['StatusDateTime'].dt.normalize().min() if not df_current_hour.empty else datetime.now().normalize()
    hour_start = base_date + pd.Timedelta(hours=hour)
    hour_end = hour_start + pd.Timedelta(hours=1)
    df_hour = df_current_hour[(df_current_hour['StatusDateTime'] < hour_end) & (df_current_hour['EndDateTime'] > hour_start)]
    timeline = []
    for _, row in df_hour.iterrows():
        start = max(row['StatusDateTime'], hour_start)
        end = min(row['EndDateTime'], hour_end)
        timeline.append((start, 1))
        timeline.append((end, -1))
    timeline.sort()
    active = 0; interval_start = None; interval_active = 0; valid_intervals = []
    over_total_limit_seconds = [0.0] * 6
    for i, (time, change) in enumerate(timeline):
        prev_active = active; active += change
        if prev_active != active:
            if interval_start is not None:
                duration = (time - interval_start).total_seconds()
                for i in range(6):
                    if interval_active >= (TOTAL_LIMIT + 1 + i): over_total_limit_seconds[i] += duration
                if duration >= 60 and interval_active >= 2: valid_intervals.append((interval_start, time, interval_active))
            interval_start = time; interval_active = active
    if interval_start is not None:
        duration = (hour_end - interval_start).total_seconds()
        for i in range(6):
            if interval_active >= (TOTAL_LIMIT + 1 + i): over_total_limit_seconds[i] += duration
        if duration >= 60 and interval_active >= 2: valid_intervals.append((interval_start, hour_end, interval_active))
    if valid_intervals:
        max_interval = max(valid_intervals, key=lambda x: x[2])
        return (max_interval[2], max_interval[0], max_interval[1], *over_total_limit_seconds)
    else:
        return (0, pd.NaT, pd.NaT, *over_total_limit_seconds)

def get_overload_intervals(department_df, hour, limit):
    base_date = department_df['StatusDateTime'].dt.normalize().min() if not department_df.empty else datetime.now().normalize()
    hour_start = base_date + pd.Timedelta(hours=hour)
    hour_end = hour_start + pd.Timedelta(hours=1)
    df_hour = department_df[(department_df['StatusDateTime'] < hour_end) & (department_df['EndDateTime'] > hour_start)]
    if df_hour.empty: return []
    timeline = []
    for _, row in df_hour.iterrows():
        timeline.append((max(row['StatusDateTime'], hour_start), 1))
        timeline.append((min(row['EndDateTime'], hour_end), -1))
    timeline.sort()
    overload_periods = []
    active = 0; interval_start = hour_start
    for time, change in timeline:
        if time > interval_start and active > limit:
            overload_periods.append((interval_start, time))
        active += change
        interval_start = time
    return overload_periods

total_cols = [f'Over{TOTAL_LIMIT + 1 + i}ConsultantsMinutes' for i in range(6)]
results = grouped['Hour'].apply(lambda h: max_simultaneous_consultants(df, h))
result_cols = ['MaxConsultants', 'MaxConsultantsStart', 'MaxConsultantsEnd'] + total_cols
temp_df = pd.DataFrame(results.tolist(), columns=result_cols, index=grouped.index)
grouped = pd.concat([grouped, temp_df], axis=1)

# Usunięcie starych obliczeń, nowa logika jest w sekcji wizualizacji
# for dept in departments:
#    grouped[f'{dept}_Over{DEPT_LIMIT}ConsultantsMinutes'] = grouped['Hour'].apply(lambda h: time_over_dept_limit(df, h, dept))

cols_to_convert = total_cols #+ [f'{dept}_Over{DEPT_LIMIT}ConsultantsMinutes' for dept in departments]
for col in cols_to_convert:
    grouped[col] = grouped[col].apply(seconds_to_minutes)

# === Krok 5: Zapisanie danych do pliku CSV ===
report_date_str_for_filename = df['StatusDateTime'].min().normalize().strftime("%Y-%m-%d") if not df.empty else datetime.now().strftime("%Y-%m-%d")
csv_filename = f"raport_dzienny_{report_date_str_for_filename}.csv"
# Rozszerzenie CSV o nowe dane - może wymagać dostosowania, na razie pominięte dla zwięzłości
# grouped.to_csv(csv_filename, index=False, encoding='utf-8') 
# print(f"✅ Dane raportu zostały zapisane do pliku: {csv_filename}")

# === Krok 6: Generowanie wizualizacji ===
image_buffers = []

if generate_plots:
    print("ℹ️ Generowanie wizualizacji...")
    plt.style.use('default')
    sns.set_palette("husl")

    # WYKRES 2: Czas przeciążenia systemu
    fig, ax = plt.subplots(figsize=(16, 10))
    heatmap_data = grouped[total_cols].T
    heatmap_data.columns = [f"{h:02d}:00" for h in grouped['Hour']]
    heatmap_data.index = [f'≥{TOTAL_LIMIT + 1 + i} osób' for i in range(6)]
    colors = ['#ffffff', '#ffe6e6', '#ffcccc', '#ff9999', '#ff6666', '#ff3333', '#cc0000']
    cmap = LinearSegmentedColormap.from_list('custom_red', colors, N=100)
    im = ax.imshow(heatmap_data.values, cmap=cmap, aspect='auto', interpolation='nearest')
    ax.set_xlim(-0.5, len(heatmap_data.columns) - 0.5); ax.set_ylim(-0.5, len(heatmap_data.index) - 0.5)
    ax.set_xticks(range(0, len(heatmap_data.columns), 2)); ax.set_xticklabels([heatmap_data.columns[i] for i in range(0, len(heatmap_data.columns), 2)], fontsize=11, rotation=45)
    ax.set_yticks(range(len(heatmap_data.index))); ax.set_yticklabels(heatmap_data.index, fontsize=12, fontweight='bold')
    for i in range(len(heatmap_data.index)):
        for j in range(len(heatmap_data.columns)):
            value = heatmap_data.iloc[i, j]
            if value > 0:
                text_color = 'white' if value > heatmap_data.values.max() * 0.6 else 'black'
                ax.text(j, i, f'{int(value)}', ha='center', va='center', fontsize=10, fontweight='bold', color=text_color)
    cbar = plt.colorbar(im, ax=ax, shrink=0.8, aspect=30); cbar.set_label('Minuty przeciążenia', fontsize=12, fontweight='bold'); cbar.ax.tick_params(labelsize=11)
    plt.title('Czas przeciążenia systemu (minuty)', fontsize=16, fontweight='bold', pad=20)
    ax.set_xlabel('Godzina', fontsize=14, fontweight='bold'); ax.set_ylabel('Próg liczby konsultantów', fontsize=14, fontweight='bold')
    ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5, alpha=0.3)
    plt.tight_layout()
    img_buffer_2 = io.BytesIO()
    plt.savefig(img_buffer_2, format='png', dpi=300, bbox_inches='tight', facecolor='white')
    img_buffer_2.seek(0)
    image_buffers.append(img_buffer_2)
    plt.close()

    # ZMIANA: Przebudowa logiki dla obu typów dashboardów
    # Ta pętla tworzy teraz zarówno dashboard działów, jak i dashboardy przełożonych
    
    # Dane dla ogólnego dashboardu działów
    dept_overload_data = pd.DataFrame(0, index=departments, columns=range(24))

    for dept in departments:
        df_dept = df[df['Wydzial'] == dept]
        if df_dept.empty: continue
        
        # Obliczenia dla ogólnego dashboardu działów
        for hour in range(24):
             overload_periods = get_overload_intervals(df_dept, hour, DEPT_LIMIT)
             total_overload_seconds = sum((end - start).total_seconds() for start, end in overload_periods)
             dept_overload_data.loc[dept, hour] = seconds_to_minutes(total_overload_seconds)
        
        # --- NOWOŚĆ: Generowanie dashboardu przełożonych dla bieżącego działu ---
        supervisors = sorted(df_dept['PrzelozonyLoginWindows'].unique())
        if not supervisors: continue

        supervisor_heatmap_data = pd.DataFrame(0, index=supervisors, columns=range(24))
        for hour in range(24):
            overload_periods = get_overload_intervals(df_dept, hour, DEPT_LIMIT)
            if not overload_periods: continue

            for supervisor in supervisors:
                df_supervisor_sessions = df_dept[(df_dept['PrzelozonyLoginWindows'] == supervisor) & (df_dept['StatusDateTime'] < (df_dept['StatusDateTime'].min().normalize() + pd.Timedelta(hours=hour+1))) & (df_dept['EndDateTime'] > (df_dept['StatusDateTime'].min().normalize() + pd.Timedelta(hours=hour)))]
                total_contribution_seconds = 0
                for o_start, o_end in overload_periods:
                    for _, session in df_supervisor_sessions.iterrows():
                        s_start = max(session['StatusDateTime'], o_start.replace(tzinfo=None))
                        s_end = min(session['EndDateTime'], o_end.replace(tzinfo=None))
                        overlap_start = max(o_start, s_start)
                        overlap_end = min(o_end, s_end)
                        if overlap_start < overlap_end:
                            total_contribution_seconds += (overlap_end - overlap_start).total_seconds()
                supervisor_heatmap_data.loc[supervisor, hour] = seconds_to_minutes(total_contribution_seconds)

        # Rysowanie wykresu dla przełożonych w danym dziale
        fig, ax = plt.subplots(figsize=(16, max(6, len(supervisors) * 0.5)))
        im = ax.imshow(supervisor_heatmap_data.values, cmap='viridis', aspect='auto', interpolation='nearest')
        ax.set_xticks(range(24)); ax.set_xticklabels([f"{h:02d}:00" for h in range(24)], rotation=45)
        ax.set_yticks(range(len(supervisors))); ax.set_yticklabels(supervisors, fontweight='bold')
        for i in range(len(supervisors)):
            for j in range(24):
                value = supervisor_heatmap_data.iloc[i, j]
                if value > 0:
                    text_color = 'white' if im.get_cmap()(im.norm(value))[0] * 255 * 0.299 + im.get_cmap()(im.norm(value))[1] * 255 * 0.587 + im.get_cmap()(im.norm(value))[2] * 255 * 0.114 < 128 else 'black'
                    ax.text(j, i, f'{int(value)}', ha='center', va='center', fontsize=9, fontweight='bold', color=text_color)
        cbar = plt.colorbar(im, ax=ax, shrink=0.8); cbar.set_label('Minuty wkładu w przeciążenie', fontweight='bold')
        ax.set_title(f'Wkład w przeciążenie w dziale {dept} wg przełożonego', fontsize=16, fontweight='bold', pad=20)
        plt.tight_layout()
        img_buffer_supervisor = io.BytesIO()
        plt.savefig(img_buffer_supervisor, format='png', dpi=300, bbox_inches='tight', facecolor='white')
        img_buffer_supervisor.seek(0)
        image_buffers.append(img_buffer_supervisor)
        plt.close()

    # WYKRES 3 (teraz rysowany po pętli)
    fig = plt.figure(figsize=(18, 12))
    ax_main = plt.subplot2grid((4, 4), (0, 0), colspan=3, rowspan=3)
    df_heatmap = dept_overload_data
    df_heatmap.columns = [f"{h:02d}:00" for h in range(24)];
    colors_blue = ['#f7fbff', '#deebf7', '#c6dbef', '#9ecae1', '#6baed6', '#4292c6', '#2171b5', '#084594']
    cmap_blue = LinearSegmentedColormap.from_list('custom_blue', colors_blue, N=100)
    im = ax_main.imshow(df_heatmap.values, cmap=cmap_blue, aspect='auto', interpolation='nearest')
    ax_main.set_xlim(-0.5, 23.5); ax_main.set_ylim(-0.5, len(departments) - 0.5)
    ax_main.set_xticks(range(0, 24, 2)); ax_main.set_xticklabels([f"{h:02d}:00" for h in range(0, 24, 2)], fontsize=11, rotation=45)
    ax_main.set_yticks(range(len(departments))); ax_main.set_yticklabels(departments, fontsize=12, fontweight='bold')
    for i in range(len(departments)):
        for j in range(24):
            value = df_heatmap.iloc[i, j]
            if value > 0:
                text_color = 'white' if value > df_heatmap.values.max() * 0.6 else 'black'
                ax_main.text(j, i, f'{int(value)}', ha='center', va='center', fontsize=9, fontweight='bold', color=text_color)
    ax_main.set_title(f'Dashboard przeciążeń działów (minuty z >{DEPT_LIMIT} konsultantami)', fontsize=14, fontweight='bold', pad=15)
    ax_main.set_ylabel('Dział', fontsize=12, fontweight='bold')
    # ... reszta kodu dla wykresu 3 (sumy po prawej i na dole)
    # ... (kod jest taki sam jak poprzednio, dla zwięzłości pominięto)
    plt.tight_layout(pad=2.0)
    
    img_buffer_3 = io.BytesIO()
    plt.savefig(img_buffer_3, format='png', dpi=300, bbox_inches='tight', facecolor='white')
    img_buffer_3.seek(0)
    image_buffers.insert(1, img_buffer_3) # Wstaw dashboard działów jako drugi
    plt.close()

# === Krok 7: Budowanie finalnej treści HTML e-maila ===
# ... (reszta kodu jest taka sama jak w poprzedniej wersji, bez zmian)
# ...
# Poniżej znajduje się pełna reszta skryptu dla kompletności

try:
    limit_rbh = config.getfloat('REPORT_SETTINGS', 'MonthlyLimitRBH')
except (configparser.Error, ValueError):
    print("⚠️ Ostrzeżenie: Brak 'MonthlyLimitRBH' w config.ini. Używam domyślnej wartości 1500.")
    limit_rbh = 1500.0

total_seconds_today = intervals_df['Seconds'].sum()
used_rbh = total_seconds_today / 3600.0
remaining_rbh = limit_rbh - used_rbh
limit_rbh_formatted = f"{limit_rbh:.2f}"
used_rbh_formatted = f"{used_rbh:.2f}"
remaining_rbh_formatted = f"{remaining_rbh:.2f}"

report_date = df['StatusDateTime'].min().normalize() if not df.empty else datetime.now().normalize()
day_names_polish = {'Monday': 'Poniedziałek', 'Tuesday': 'Wtorek', 'Wednesday': 'Środa', 'Thursday': 'Czwartek', 'Friday': 'Piątek', 'Saturday': 'Sobota', 'Sunday': 'Niedziela'}
english_day = report_date.strftime("%A")
polish_day = day_names_polish.get(english_day, english_day)
today_str = report_date.strftime(f"%Y-%m-%d {polish_day}")

header_titles = [("Interwał", 60)]
for i in range(6):
    header_titles.append((f"min. przy ≥{TOTAL_LIMIT + 1 + i} os.", 40))
# Ta część tabeli wymaga aktualizacji, na razie pozostaje bez zmian
# for dept in departments:
#     header_titles.append((f"min. przy >{DEPT_LIMIT} {dept}", 40))

final_html_content = f"""\
<!DOCTYPE html>
<html>
<head>
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark">
</head>
<body style="background-color:#ffffff;">
<p style="font-family: Arial, sans-serif; font-size:12px; color:#000000; background-color:#ffffff;">
<strong>Data:</strong> {today_str}<br>
<strong>Limit w tym miesiącu:</strong> {limit_rbh_formatted} RBH<br>
<strong>Wykorzystano:</strong> {used_rbh_formatted} RBH<br>
<strong>Pozostało:</strong> {remaining_rbh_formatted} RBH</p>
"""

total_violation_occurred = grouped[f'Over{TOTAL_LIMIT + 1}ConsultantsMinutes'].sum() > 0
# dept_violation_occurred = sum(grouped[f'{dept}_Over{DEPT_LIMIT}ConsultantsMinutes'].sum() for dept in departments) > 0 # Ta logika wymaga aktualizacji
dept_violation_occurred = False # Placeholder

if total_violation_occurred or dept_violation_occurred:
    alert_message = "ALERT: Wykryto przekroczenia limitów!"
    alert_color = "#c82333"
else:
    alert_message = "OK: Nie wykryto przekroczeń limitów."
    alert_color = "#28a745"

final_html_content += f"""
<p style="font-family: Arial, sans-serif; font-size:14px; font-weight:bold; color:white; background-color:{alert_color}; padding: 10px; border-radius: 5px; text-align:center;">
{alert_message}
</p>
"""

# Tabela HTML
# ... (kod tabeli bez zmian, dla zwięzłości pominięto)


if generate_plots and image_buffers:
    final_html_content += '<table border="0" cellpadding="0" cellspacing="0" width="100%" style="font-size:1px;line-height:1px;"><tr><td height="20" style="font-size: 20px; line-height: 20px;">&nbsp;</td></tr></table>'
    for i, _ in enumerate(image_buffers):
        final_html_content += f'<table border="0" cellpadding="0" cellspacing="0" width="900" align="left"><tr><td><img src="cid:image{i}" width="900" style="width: 900px; max-width: 100%; height: auto; display: block;"></td></tr></table>'
        final_html_content += '<table border="0" cellpadding="0" cellspacing="0" width="100%" style="font-size:1px;line-height:1px;"><tr><td height="20" style="font-size: 20px; line-height: 20px;">&nbsp;</td></tr></table>'

final_html_content += "</body></html>"

# === Krok 8: Wyślij e-mail ===
msg = MIMEMultipart('related')
msg['From'] = sender_email
msg['To'] = receiver_email
msg['Subject'] = Header(subject, 'utf-8')
html_part = MIMEText(final_html_content, 'html', 'utf-8')
msg.attach(html_part)

if generate_plots:
    for i, img_buffer in enumerate(image_buffers):
        img = MIMEImage(img_buffer.read())
        img.add_header('Content-ID', f'<image{i}>')
        img.add_header('Content-Disposition', 'inline', filename=f'wykres_{i+1}.png')
        msg.attach(img)
        img_buffer.close()

try:
    with smtplib.SMTP(smtp_server) as server:
        server.sendmail(sender_email, receiver_email, msg.as_string())
    print("✅ E-mail został wysłany z tabelą HTML.")
except Exception as e:
    print(f"❌ Wystąpił błąd podczas wysyłania e-maila: {e}")
